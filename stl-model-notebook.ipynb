{"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"51db6cdfef54451398948d99f70f9cdf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_35268521c7e2477797ba2e48fec197af","IPY_MODEL_ce18345c5ef34daa9afb7386a6ace169","IPY_MODEL_6894fdde2d27439693885a9587168713"],"layout":"IPY_MODEL_6890f3386b9649a28271165a809fdf2b"}},"35268521c7e2477797ba2e48fec197af":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e2817d024bb147f88fd7ce6031ffc8b7","placeholder":"​","style":"IPY_MODEL_bc33194cf78a43438b1f6b084defbd0b","value":"tokenizer_config.json: 100%"}},"ce18345c5ef34daa9afb7386a6ace169":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3fc7df04b7734c2a8dd9dd84412146ca","max":25,"min":0,"orientation":"horizontal","style":"IPY_MODEL_614533dcded349edb6924864d8b43b1c","value":25}},"6894fdde2d27439693885a9587168713":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ee35f65e383d4d2c8460269ee24a5443","placeholder":"​","style":"IPY_MODEL_e2b2789dcd3f4253b65e58989cf3375a","value":" 25.0/25.0 [00:00&lt;00:00, 1.25kB/s]"}},"6890f3386b9649a28271165a809fdf2b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e2817d024bb147f88fd7ce6031ffc8b7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc33194cf78a43438b1f6b084defbd0b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3fc7df04b7734c2a8dd9dd84412146ca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"614533dcded349edb6924864d8b43b1c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ee35f65e383d4d2c8460269ee24a5443":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e2b2789dcd3f4253b65e58989cf3375a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"41c98b0b418e4086bf42e5da27632f76":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d2e9e86be7054789b551665d36465912","IPY_MODEL_77f37f360f694c2e9a07ce6886488fc2","IPY_MODEL_de0bd2304f4e437fb3f5b705587a2c9d"],"layout":"IPY_MODEL_69a664c5b3e2432c93186c421d0d8357"}},"d2e9e86be7054789b551665d36465912":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c10774e2012044819185618ad949b0b1","placeholder":"​","style":"IPY_MODEL_47a38d6bfc824be4a63f112ba66b49b7","value":"vocab.json: 100%"}},"77f37f360f694c2e9a07ce6886488fc2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_16c0a708336d4eefb85b370c12921655","max":898823,"min":0,"orientation":"horizontal","style":"IPY_MODEL_60e38924d0124f9fb74b2d62e3db3af9","value":898823}},"de0bd2304f4e437fb3f5b705587a2c9d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f2d4458c48ce43d98a48894cf203ac96","placeholder":"​","style":"IPY_MODEL_d813abfe5d2e49779339f4aca3909ee6","value":" 899k/899k [00:00&lt;00:00, 12.0MB/s]"}},"69a664c5b3e2432c93186c421d0d8357":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c10774e2012044819185618ad949b0b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"47a38d6bfc824be4a63f112ba66b49b7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"16c0a708336d4eefb85b370c12921655":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"60e38924d0124f9fb74b2d62e3db3af9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f2d4458c48ce43d98a48894cf203ac96":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d813abfe5d2e49779339f4aca3909ee6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bfd2259b187544528565be35362011e7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5b393a1d52b247f9b158178a7eb71a84","IPY_MODEL_5bff9af011694afa9fa15a0394d37d8a","IPY_MODEL_476c0a03a97b4ca1bc86b495c48e131e"],"layout":"IPY_MODEL_9c976f25cccd46c59ec6c7860b020610"}},"5b393a1d52b247f9b158178a7eb71a84":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d690c98454994537ac774cc2fdb7d505","placeholder":"​","style":"IPY_MODEL_d8f6aedfebcf41a79cdcf607ae538f98","value":"merges.txt: 100%"}},"5bff9af011694afa9fa15a0394d37d8a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9ef37d9433ec4257be9ea53e179db3fb","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dced3ba532004b08ad04ef858b76a8fc","value":456318}},"476c0a03a97b4ca1bc86b495c48e131e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fad63bb209014646a70d470ec49bd0dd","placeholder":"​","style":"IPY_MODEL_4d5869a73b41423e8296f357fbe0dca8","value":" 456k/456k [00:00&lt;00:00, 24.9MB/s]"}},"9c976f25cccd46c59ec6c7860b020610":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d690c98454994537ac774cc2fdb7d505":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d8f6aedfebcf41a79cdcf607ae538f98":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9ef37d9433ec4257be9ea53e179db3fb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dced3ba532004b08ad04ef858b76a8fc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fad63bb209014646a70d470ec49bd0dd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4d5869a73b41423e8296f357fbe0dca8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"28e58c43ccc54d7687cf2453b9ace33b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c2dbbee5e1974107a2a973b3c146b210","IPY_MODEL_95792e980c9e439282a6f20e97f957d6","IPY_MODEL_2e3962be6bd146e393f01306d2445112"],"layout":"IPY_MODEL_33cd9a1c30714aa5b15474c9e0a72676"}},"c2dbbee5e1974107a2a973b3c146b210":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_48ea3bf028f944c09a17049cdea51d39","placeholder":"​","style":"IPY_MODEL_c83fd0b0886346db889e2d43d63c23ff","value":"tokenizer.json: 100%"}},"95792e980c9e439282a6f20e97f957d6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5b8efb8bf4e74ba89fe983e36f74f61c","max":1355863,"min":0,"orientation":"horizontal","style":"IPY_MODEL_76566a77b9454ce7b4c5e408df90742a","value":1355863}},"2e3962be6bd146e393f01306d2445112":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bff7df8ca80141e5862bd3c92fea2b66","placeholder":"​","style":"IPY_MODEL_aa7b3a6160f24bf98533d7bf4dc62c67","value":" 1.36M/1.36M [00:00&lt;00:00, 42.1MB/s]"}},"33cd9a1c30714aa5b15474c9e0a72676":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"48ea3bf028f944c09a17049cdea51d39":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c83fd0b0886346db889e2d43d63c23ff":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5b8efb8bf4e74ba89fe983e36f74f61c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"76566a77b9454ce7b4c5e408df90742a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bff7df8ca80141e5862bd3c92fea2b66":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aa7b3a6160f24bf98533d7bf4dc62c67":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"df132b3615304ec3ba571d5c3f34ad2d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_94227ec9c3364b58b2514f59fc921bd1","IPY_MODEL_23eb1ccf4c0d48ff86c89bfa0e70981f","IPY_MODEL_b5b15ea2575b4f8ea1a39346d292828d"],"layout":"IPY_MODEL_393b5c68ca8d441d8e7bbede30276acf"}},"94227ec9c3364b58b2514f59fc921bd1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ad994d9f906641ae941e67d5bd1a1feb","placeholder":"​","style":"IPY_MODEL_53747121847149b093672b9064efd99a","value":"config.json: 100%"}},"23eb1ccf4c0d48ff86c89bfa0e70981f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3c48669cfaf84e45852cb7658c5ae262","max":481,"min":0,"orientation":"horizontal","style":"IPY_MODEL_59592a95b7174a518b4ae787d5b4c577","value":481}},"b5b15ea2575b4f8ea1a39346d292828d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c37d9b2713b24432b5c05af3058ccabb","placeholder":"​","style":"IPY_MODEL_2b9c0e4f96194a8db41f4f8d928e73e2","value":" 481/481 [00:00&lt;00:00, 32.1kB/s]"}},"393b5c68ca8d441d8e7bbede30276acf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ad994d9f906641ae941e67d5bd1a1feb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"53747121847149b093672b9064efd99a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3c48669cfaf84e45852cb7658c5ae262":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"59592a95b7174a518b4ae787d5b4c577":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c37d9b2713b24432b5c05af3058ccabb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2b9c0e4f96194a8db41f4f8d928e73e2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0128e0d025384d9cbbedf196a6d59453":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_149014f6cce246979abccc2319eeee30","IPY_MODEL_cef01a223f044df88d8f0710f374cb64","IPY_MODEL_52d91f406170492385833b1fffdd7ca5"],"layout":"IPY_MODEL_062c6f8e073d49218d8315e49bd68e82"}},"149014f6cce246979abccc2319eeee30":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_10ce5d30188340e1a0bd71a78772ad0c","placeholder":"​","style":"IPY_MODEL_a8519154088647f6960ed7ce94be84c9","value":"model.safetensors: 100%"}},"cef01a223f044df88d8f0710f374cb64":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f01a3ba71c5e4777b3e511c2cb64255c","max":498818054,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dcbdba8201fc493488dbae1475939989","value":498818054}},"52d91f406170492385833b1fffdd7ca5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_03168e27dfeb4bae949b8bf8b052d091","placeholder":"​","style":"IPY_MODEL_fc26e698de3e4450b568468d0a2bd9bc","value":" 499M/499M [00:02&lt;00:00, 184MB/s]"}},"062c6f8e073d49218d8315e49bd68e82":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"10ce5d30188340e1a0bd71a78772ad0c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a8519154088647f6960ed7ce94be84c9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f01a3ba71c5e4777b3e511c2cb64255c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dcbdba8201fc493488dbae1475939989":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"03168e27dfeb4bae949b8bf8b052d091":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fc26e698de3e4450b568468d0a2bd9bc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Entity Extraction in Comparative Analysis\n\nEntity extraction is fundamental to comparative analysis as it identifies the core subjects of comparison within subjective comparative questions. This involves pinpointing and categorizing the entities (such as products, services, or features) that are being compared. Effective entity extraction ensures that each comparative relation is anchored to clear, identifiable elements, making the subsequent analysis more structured and interpretable. This process is essential for constructing a reliable foundation for further comparative assessments and is integral to developing accurate and context-aware NLP solutions.\n","metadata":{}},{"cell_type":"markdown","source":"## Setting Up the Environment\n\nBefore diving into our classification project, we must ensure our Python environment has all the necessary libraries. We'll use the `transformers` library for accessing pre-trained models like RoBERTa, which is essential for our NLP tasks. PyTorch, along with its `torchvision` and `torchaudio` libraries, provides a comprehensive ecosystem for building and training deep learning models. Additionally, scikit-learn offers valuable tools for data preprocessing, model evaluation, and implementing cross-validation strategies.\n\n**Required Libraries:**\n\n* **transformers:** Provides pre-trained models for various NLP tasks.\n* **torch, torchvision, torchaudio:** PyTorch ecosystem for deep learning operations.\n* **scikit-learn:** Offers machine learning tools for data manipulation and model evaluation.\n\n**Installation:**\n\nYou can install these libraries using `pip` within a code cell:","metadata":{}},{"cell_type":"code","source":"#!pip install --upgrade transformers\n!pip install torch torchvision torchaudio\n!pip install transformers\n!pip install scikit-learn","metadata":{"execution":{"iopub.status.busy":"2024-03-29T11:17:36.316094Z","iopub.execute_input":"2024-03-29T11:17:36.316498Z","iopub.status.idle":"2024-03-29T11:18:13.124045Z","shell.execute_reply.started":"2024-03-29T11:17:36.316458Z","shell.execute_reply":"2024-03-29T11:18:13.122926Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.1.2)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (0.16.2)\nRequirement already satisfied: torchaudio in /opt/conda/lib/python3.10/site-packages (2.1.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.3.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision) (1.26.4)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision) (2.31.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision) (9.5.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (2024.2.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.38.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.21.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.2)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.3.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (1.2.2)\nRequirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.26.4)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.11.4)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.3.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (3.2.0)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Data Acquisition\n\nBefore diving into the intricacies of our Element Extraction model, the first crucial step is to acquire the relevant dataset. In the following code snippet, we utilize the `requests` library to download a pre-compiled dataset from a specified URL. Upon successful download, we proceed to unzip\n","metadata":{}},{"cell_type":"code","source":"import requests\nimport zipfile\nimport os\n\ndata_url = \"https://github.com/mahsamb/SCRQD/raw/main/Dataset.zip\"\nzip_filename = \"Dataset.zip\"\n\n# Downloading using requests\nresponse = requests.get(data_url)\n\n# Check if the request was successful (status_code 200)\nif response.status_code == 200:\n    with open(zip_filename, \"wb\") as f:\n        f.write(response.content)\nelse:\n    print(f\"Failed to retrieve the data: {response.status_code}: {response.text}\")\n    # Add additional error handling here\n\n# Unzipping the dataset\ntry:\n    with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n        zip_ref.extractall(\"data\")\n    print(\"Files extracted:\")\n    print(os.listdir(\"data\"))\nexcept zipfile.BadZipFile:\n    print(\"Error: The file doesn’t appear to be a valid zip file\")\n","metadata":{"execution":{"iopub.status.busy":"2024-03-29T11:18:13.126017Z","iopub.execute_input":"2024-03-29T11:18:13.126324Z","iopub.status.idle":"2024-03-29T11:18:13.442771Z","shell.execute_reply.started":"2024-03-29T11:18:13.126295Z","shell.execute_reply":"2024-03-29T11:18:13.441680Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Files extracted:\n['Questions.pkl', 'Elements.pkl', 'Relations.pkl', 'EntityRoles.pkl', 'ComparativePreferences.pkl']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Preparing the Environment and Loading Data\n\nTo ensure our Element Extraction model functions effectively, we start by setting up our environment with essential libraries such as `numpy` and `pandas` for data manipulation, and `re` for regular expressions, which are critical for processing text data. Additionally, we use `pickle` for loading our\n","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pickle as cPickle\nimport pickle\nimport re\nimport pandas as pd\nfrom IPython.display import display, HTML\nimport random\n\n\n\nwith open(r\"/kaggle/working/data/Questions.pkl\", \"rb\") as input_file:\n    QuestionDict = pickle.load(input_file)\n    input_file.close()\n\n\nwith open(r\"/kaggle/working/data/Elements.pkl\", \"rb\") as input_file:\n    Product_Aspect_Contraint_dict = pickle.load(input_file)\n    input_file.close()","metadata":{"execution":{"iopub.status.busy":"2024-03-29T11:18:13.443776Z","iopub.execute_input":"2024-03-29T11:18:13.444023Z","iopub.status.idle":"2024-03-29T11:18:14.524430Z","shell.execute_reply.started":"2024-03-29T11:18:13.444001Z","shell.execute_reply":"2024-03-29T11:18:14.523634Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Initial Exploration of Loaded Datasets\n\nWith our datasets loaded into Python dictionaries, it's essential to begin with an initial exploration to understand the structure and type of data we'll be working with. In the code snippets provided, we iterate through both `Product_Aspect_Contraint_dict` and `QuestionDict`, printing the first key-value pair of each to get a glimpse into the data. This preliminary step is crucial for ensuring the integrity of our data and to familiarize ourselves with the dataset's format, which will inform our strategy for the Element Extraction process.\n","metadata":{}},{"cell_type":"code","source":"for key, value in Product_Aspect_Contraint_dict.items():\n  print(key)\n  print(value)\n  break\n\nfor key, value in QuestionDict.items():\n  print(key)\n  print(value)\n  break","metadata":{"execution":{"iopub.status.busy":"2024-03-29T11:18:14.527146Z","iopub.execute_input":"2024-03-29T11:18:14.527653Z","iopub.status.idle":"2024-03-29T11:18:14.533275Z","shell.execute_reply.started":"2024-03-29T11:18:14.527619Z","shell.execute_reply":"2024-03-29T11:18:14.532377Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"1\n[['O-P O-P O-P O-P O-P O-P O-P O-P O-P O-P O-P O-P O-P O-P O-P O-P O-P O-P O-P O-P O-P B-P O-P'], ['O-A O-A O-A O-A O-A O-A O-A B-A I-A I-A I-A O-A O-A O-A B-A I-A O-A B-A O-A O-A O-A O-A O-A'], ['O-C O-C O-C O-C B-C B-C I-C I-C I-C I-C I-C O-C O-C O-C O-C O-C O-C O-C O-C B-C I-C I-C O-C']]\n1\nWhat are the best smartphones with a built in stylus feature with a good quality display and RAM , other than Samsung ?\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Constructing the Data Structure for Model Input\n\nAfter our initial exploration, the next step involves structuring our data into a format suitable for our Element Extraction model. The provided code snippet accomplishes this by iterating over the `QuestionDict` and corresponding `Product_Aspect_Contraint_dict` to create a comprehensive list of dictionaries, each containing a question and its associated entity, aspect, and constraint labels. This structured approach facilitates the easy manipulation and analysis of our dataset, preparing it for the model training phase. By aligning our questions with their respective labels in a unified data structure, we ensure a smooth transition into the model's training and evaluation stages.\n","metadata":{}},{"cell_type":"code","source":"data = []\n\nfor key, value in QuestionDict.items():\n    question_text = value  # The question text from QuestionDict\n    label_info = Product_Aspect_Contraint_dict[key]  # The corresponding labels from Product_Aspect_Constraint_dict\n\n    # Extract label lists directly from label_info without trying to split them\n    entity_labels, aspect_labels, constraint_labels = label_info\n\n    # Since label_info items are already lists, we can directly use them\n    # Adjust the structure as needed based on your exact format\n\n    data_entry = {\n        \"text\": question_text,\n        \"entity_labels\": entity_labels,  # No need to wrap in another list or call split\n        \"aspect_labels\": aspect_labels,\n        \"constraint_labels\": constraint_labels\n    }\n\n    data.append(data_entry)","metadata":{"execution":{"iopub.status.busy":"2024-03-29T11:18:14.534633Z","iopub.execute_input":"2024-03-29T11:18:14.535280Z","iopub.status.idle":"2024-03-29T11:18:14.544586Z","shell.execute_reply.started":"2024-03-29T11:18:14.535216Z","shell.execute_reply":"2024-03-29T11:18:14.543677Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## Previewing Structured Data Entries\n\nTo verify the integrity and structure of our newly constructed data entries, we print the first item from our prepared data list. This step is crucial for ensuring that our data is correctly formatted and contains all necessary information for the Element Extraction tasks. By examining this sample entry, we can confirm the successful preparation of our data, setting the stage for the subsequent model training and evaluation processes.\n","metadata":{}},{"cell_type":"code","source":"for item in data:\n    print(item)\n    #print(item.type)\n    break","metadata":{"execution":{"iopub.status.busy":"2024-03-29T11:18:14.545658Z","iopub.execute_input":"2024-03-29T11:18:14.546004Z","iopub.status.idle":"2024-03-29T11:18:14.555254Z","shell.execute_reply.started":"2024-03-29T11:18:14.545974Z","shell.execute_reply":"2024-03-29T11:18:14.554416Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"{'text': 'What are the best smartphones with a built in stylus feature with a good quality display and RAM , other than Samsung ?', 'entity_labels': ['O-P O-P O-P O-P O-P O-P O-P O-P O-P O-P O-P O-P O-P O-P O-P O-P O-P O-P O-P O-P O-P B-P O-P'], 'aspect_labels': ['O-A O-A O-A O-A O-A O-A O-A B-A I-A I-A I-A O-A O-A O-A B-A I-A O-A B-A O-A O-A O-A O-A O-A'], 'constraint_labels': ['O-C O-C O-C O-C B-C B-C I-C I-C I-C I-C I-C O-C O-C O-C O-C O-C O-C O-C O-C B-C I-C I-C O-C']}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Refining Label Formats for Analysis\n\nBefore we proceed with training our Element Extraction model, it's imperative to refine the format of our labels to ensure compatibility with our processing algorithms. This code snippet updates each data entry by splitting the label strings into lists of individual labels. This step transforms our previously structured label information into a more granular and model-friendly format, enabling precise tagging and classification during the training phase. By adjusting the label format, we enhance the model's ability to learn from and accurately predict the elements within our dataset.\n\n","metadata":{}},{"cell_type":"code","source":"# Iterate through each dictionary in the list\nfor item in data:\n    # Splitting the labels based on space ' ' and updating the values\n    item['entity_labels'] = item['entity_labels'][0].split()\n    item['aspect_labels'] = item['aspect_labels'][0].split()\n    item['constraint_labels'] = item['constraint_labels'][0].split()\n\n#print(data)\nfor item in data:\n    print(item)\n    break","metadata":{"execution":{"iopub.status.busy":"2024-03-29T11:18:14.556164Z","iopub.execute_input":"2024-03-29T11:18:14.556413Z","iopub.status.idle":"2024-03-29T11:18:14.572308Z","shell.execute_reply.started":"2024-03-29T11:18:14.556391Z","shell.execute_reply":"2024-03-29T11:18:14.571433Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"{'text': 'What are the best smartphones with a built in stylus feature with a good quality display and RAM , other than Samsung ?', 'entity_labels': ['O-P', 'O-P', 'O-P', 'O-P', 'O-P', 'O-P', 'O-P', 'O-P', 'O-P', 'O-P', 'O-P', 'O-P', 'O-P', 'O-P', 'O-P', 'O-P', 'O-P', 'O-P', 'O-P', 'O-P', 'O-P', 'B-P', 'O-P'], 'aspect_labels': ['O-A', 'O-A', 'O-A', 'O-A', 'O-A', 'O-A', 'O-A', 'B-A', 'I-A', 'I-A', 'I-A', 'O-A', 'O-A', 'O-A', 'B-A', 'I-A', 'O-A', 'B-A', 'O-A', 'O-A', 'O-A', 'O-A', 'O-A'], 'constraint_labels': ['O-C', 'O-C', 'O-C', 'O-C', 'B-C', 'B-C', 'I-C', 'I-C', 'I-C', 'I-C', 'I-C', 'O-C', 'O-C', 'O-C', 'O-C', 'O-C', 'O-C', 'O-C', 'O-C', 'B-C', 'I-C', 'I-C', 'O-C']}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Applying Label Encoding for Machine Learning\n\nThe final preprocessing step involves converting our textual labels into numerical representations, a process known as label encoding. This transformation is crucial for machine learning models, which require numerical input. Using a predefined mapping dictionary, we replace the textual labels in our dataset with their corresponding numerical codes. This encoding not only simplifies the model's input but also ensures that the training process is optimized for efficiency and accuracy. By examining a sample entry after this transformation, we can confirm the readiness of our data for the upcoming machine learning tasks.","metadata":{}},{"cell_type":"code","source":"# Mapping dictionary\nlabel_map = {\"O-P\": 0, \"B-P\": 1, \"I-P\": 2, \"O-A\": 0, \"B-A\": 1, \"I-A\": 2, \"O-C\": 0, \"B-C\": 1, \"I-C\": 2}\n\n# Iterate through each dictionary in the list\nfor item in data:\n    # Replace entity_labels\n    item['entity_labels'] = [label_map[label] for label in item['entity_labels']]\n    # Replace aspect_labels\n    item['aspect_labels'] = [label_map[label] for label in item['aspect_labels']]\n    # Replace constraint_labels\n    item['constraint_labels'] = [label_map[label] for label in item['constraint_labels']]\n\n    #print(data)\nfor item in data:\n    print(item)\n    break","metadata":{"execution":{"iopub.status.busy":"2024-03-29T11:18:14.573521Z","iopub.execute_input":"2024-03-29T11:18:14.574112Z","iopub.status.idle":"2024-03-29T11:18:14.591795Z","shell.execute_reply.started":"2024-03-29T11:18:14.574082Z","shell.execute_reply":"2024-03-29T11:18:14.590908Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"{'text': 'What are the best smartphones with a built in stylus feature with a good quality display and RAM , other than Samsung ?', 'entity_labels': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], 'aspect_labels': [0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 0, 0, 0, 1, 2, 0, 1, 0, 0, 0, 0, 0], 'constraint_labels': [0, 0, 0, 0, 1, 1, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0]}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Displaying Processed Data and Labels\n\nTo confirm that our data is correctly processed and ready for the next steps, we display the text, entity labels, aspect labels, and constraint labels of the first entry in our prepared dataset. This visualization allows us to ensure that the textual data aligns with its corresponding numerical labels, indicating successful label encoding and data structuring. It's a vital checkpoint to verify the data's readiness for model training and analysis.","metadata":{}},{"cell_type":"code","source":"print(data[0]['text'])\nprint(data[0]['entity_labels'])\nprint(data[0]['aspect_labels'])\nprint(data[0]['constraint_labels'])","metadata":{"execution":{"iopub.status.busy":"2024-03-29T11:18:14.594212Z","iopub.execute_input":"2024-03-29T11:18:14.594537Z","iopub.status.idle":"2024-03-29T11:18:14.605403Z","shell.execute_reply.started":"2024-03-29T11:18:14.594514Z","shell.execute_reply":"2024-03-29T11:18:14.604475Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"What are the best smartphones with a built in stylus feature with a good quality display and RAM , other than Samsung ?\n[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 0, 0, 0, 1, 2, 0, 1, 0, 0, 0, 0, 0]\n[0, 0, 0, 0, 1, 1, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Organizing Data for Easy Access\n\nAs we move forward, organizing our data in a manner that facilitates easy access and manipulation becomes crucial. By categorizing the processed data into separate dictionaries for entities, aspects, and constraints, we enhance our ability to swiftly retrieve and analyze specific segments of our dataset. This organization not only aids in data management but also in performing focused analyses on different elements of the text. Displaying the structured data for the first entry further solidifies our understanding of the dataset's organization and prepares us for detailed element extraction tasks.","metadata":{}},{"cell_type":"code","source":"# Assuming \"data\" is a list of dictionaries, each structured like the example you provided\n\n# Initialize three empty dictionaries\nentity_dict, aspect_dict, constraint_dict = {}, {}, {}\n\n# Iterate through each item in the data list\nfor item in data:\n    # Extract and assign the relevant information to each dictionary\n    entity_dict[item['text']] = item['entity_labels']\n    aspect_dict[item['text']] = item['aspect_labels']\n    constraint_dict[item['text']] = item['constraint_labels']\n\n# Example to show the result for the first item in the list\nprint(\"Text:\", data[0]['text'])\nprint(\"Entity Labels:\", entity_dict[data[0]['text']])\nprint(\"Aspect Labels:\", aspect_dict[data[0]['text']])\nprint(\"Constraint Labels:\", constraint_dict[data[0]['text']])\n","metadata":{"execution":{"iopub.status.busy":"2024-03-29T11:18:14.608784Z","iopub.execute_input":"2024-03-29T11:18:14.609089Z","iopub.status.idle":"2024-03-29T11:18:14.617981Z","shell.execute_reply.started":"2024-03-29T11:18:14.609066Z","shell.execute_reply":"2024-03-29T11:18:14.617325Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Text: What are the best smartphones with a built in stylus feature with a good quality display and RAM , other than Samsung ?\nEntity Labels: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\nAspect Labels: [0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 0, 0, 0, 1, 2, 0, 1, 0, 0, 0, 0, 0]\nConstraint Labels: [0, 0, 0, 0, 1, 1, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Extracting and Demonstrating Key-Value Pair Relationships\n\nThe function `extract_values` is designed to map keys from one list to values in another, based on a reference dictionary. This is particularly useful in scenarios where we need to align different elements of our dataset, such as texts and their corresponding labels, for detailed analysis or processing. Following this, we showcase the utility of this function by preparing to align texts with their labels for entities, aspects, and constraints separately. By extracting and printing the first elements of these lists, we prepare to demonstrate how texts and labels can be effectively paired, providing a clear foundation for any subsequent operations that require a direct association between textual data and their annotated labels.","metadata":{}},{"cell_type":"code","source":"def extract_values(dict1, list1, list2):\n    result = {}\n    for key, value in zip(list1, list2):\n        result[key] = dict1.get(value, None)\n    return result\n\n\nentity_text_ = list(entity_dict.keys())\nentity_labels_ = list(entity_dict.values())\n\nprint(\"list1:\", entity_text_[0])\nprint(\"list2:\", entity_labels_[0])\n\n\naspect_text_ = list(aspect_dict.keys())\naspect_labels_ = list(aspect_dict.values())\n\nprint(\"list1:\", aspect_text_[0])\nprint(\"list2:\", aspect_labels_[0])\n\n\nconstraint_text_ = list(constraint_dict.keys())\nconstraint_labels_ = list(constraint_dict.values())\n\nprint(\"list1:\", constraint_text_[0])\nprint(\"list2:\", constraint_labels_[0])","metadata":{"execution":{"iopub.status.busy":"2024-03-29T11:18:14.628323Z","iopub.execute_input":"2024-03-29T11:18:14.628573Z","iopub.status.idle":"2024-03-29T11:18:14.637896Z","shell.execute_reply.started":"2024-03-29T11:18:14.628543Z","shell.execute_reply":"2024-03-29T11:18:14.636980Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"list1: What are the best smartphones with a built in stylus feature with a good quality display and RAM , other than Samsung ?\nlist2: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\nlist1: What are the best smartphones with a built in stylus feature with a good quality display and RAM , other than Samsung ?\nlist2: [0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 0, 0, 0, 1, 2, 0, 1, 0, 0, 0, 0, 0]\nlist1: What are the best smartphones with a built in stylus feature with a good quality display and RAM , other than Samsung ?\nlist2: [0, 0, 0, 0, 1, 1, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Preparing Data for RoBERTa Token Classification\n\nTo fine-tune the RoBERTa model for token classification, we first import necessary modules and initialize the RoBERTa tokenizer and model with the appropriate number of labels for our classification task. We then proceed to preprocess our entity texts and labels for model input. This involves tokenizing the texts, creating attention masks for handling padding, and adjusting label lengths to match the tokenized inputs. Padding labels with -100 ensures that these positions are ignored during the loss calculation, aligning with the model's requirements. By converting these lists into tensors, we prepare our dataset for training with RoBERTa, setting the stage for effective learning and classification of entities, aspects, and constraints within our text data.","metadata":{}},{"cell_type":"code","source":"import torch\nfrom transformers import RobertaTokenizer, RobertaForTokenClassification\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.model_selection import KFold\nimport numpy as np\n\ntokenizer = RobertaTokenizer.from_pretrained('roberta-base')\nmodel = RobertaForTokenClassification.from_pretrained('roberta-base', num_labels=3)\n\n\nmax1=100\nmax_length = max1  # Adjust as needed\n\ninput_ids = []\nattention_masks = []\nentity_labels = []\n\ntexts=[]\nlabels=[]\n\ntexts = entity_text_\nlabels = entity_labels_\n\nfor text, label in zip(texts, labels):\n    encoded_dict = tokenizer.encode_plus(\n                        text,\n                        add_special_tokens=True,\n                        max_length=max_length,\n                        padding='max_length',\n                        truncation=True,\n                        return_attention_mask=True,\n                        return_tensors='pt',\n                    )\n\n    # Create a mask for the labels to ignore padding in the loss computation\n    label_mask = [1] * len(label) + [0] * (max_length - len(label))\n    label = label + [-100] * (max_length - len(label))  # Padding labels with -100, which is ignored by the loss function\n\n    input_ids.append(encoded_dict['input_ids'])\n    attention_masks.append(encoded_dict['attention_mask'])\n    entity_labels.append(label)\n\nentity_input_ids = torch.cat(input_ids, dim=0)\nentity_attention_masks = torch.cat(attention_masks, dim=0)\nentity_labels = torch.tensor(entity_labels)\n\n# Proceed with dataset creation, DataLoader setup, and cross-validation as before","metadata":{"execution":{"iopub.status.busy":"2024-03-29T11:18:14.638967Z","iopub.execute_input":"2024-03-29T11:18:14.639294Z","iopub.status.idle":"2024-03-29T11:18:29.432553Z","shell.execute_reply.started":"2024-03-29T11:18:14.639265Z","shell.execute_reply":"2024-03-29T11:18:29.431509Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"52876176ffec4f6eb4590ea8a6831421"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e8a8c52f4894a72a2460c5f5937c6b2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4eabc837f2e543eea9ca53728c1b70a7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f2356a14d65d4100852a354ca38bbb5f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72ac78cc67814e2a95442baa27c32fbc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a94a46cfdc040629f4ffc60bd4a7fd6"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Implementing K-Fold Cross-Validation for Model Evaluation\nTo rigorously evaluate our RoBERTa model's performance on the entity classification task, we employ a K-Fold cross-validation strategy. This method divides our dataset into five distinct folds, systematically using each fold as a validation set while training on the remaining data. Throughout the training process, we adjust the model's parameters using the Adam optimizer and track metrics such as loss and accuracy for both training and validation phases. By calculating precision, recall, and F1-score after each fold, we gain insights into the model's generalization ability and its performance across different subsets of the data. This comprehensive evaluation approach not only helps in fine-tuning the model's parameters but also ensures that we develop a robust and reliable classification system.","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset, Subset\nfrom transformers import RobertaModel\n#from transformers import AdamW\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import precision_recall_fscore_support, accuracy_score\nimport numpy as np\nfrom tqdm.auto import tqdm\nfrom torch.optim import Adam,AdamW\nfrom transformers import get_linear_schedule_with_warmup\nfrom torch.utils.data.dataset import random_split\n\n\n\nnum_labels = 3\nnum_epochs = 5\n\nclass SingleTaskRoberta(nn.Module):\n    def __init__(self, num_labels):\n        super().__init__()\n        self.roberta = RobertaModel.from_pretrained('roberta-base')\n        self.classifier = nn.Linear(self.roberta.config.hidden_size, num_labels)\n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n        sequence_output = outputs.last_hidden_state\n        logits = self.classifier(sequence_output)\n        return logits\n    \n\n\nclass TokenClassificationDataset(Dataset):\n    def __init__(self, input_ids, attention_masks, labels):\n        self.input_ids = input_ids\n        self.attention_masks = attention_masks\n        self.labels = labels\n\n    def __len__(self):\n        return len(self.input_ids)\n\n    def __getitem__(self, idx):\n        return {\n            'input_ids': self.input_ids[idx],\n            'attention_mask': self.attention_masks[idx],\n            'labels': self.labels[idx],\n        }\n\n# Function to compute accuracy\ndef calculate_accuracy(logits, labels):\n    preds = torch.argmax(logits, dim=-1)\n    mask = labels != -100\n    preds = preds[mask]\n    labels = labels[mask]\n    accuracy = (preds == labels).float().mean()\n    return accuracy.item()\n\n\n# Initialize your single_task_dataset here with your real data\nsingle_task_dataset = TokenClassificationDataset(entity_input_ids, entity_attention_masks, entity_labels)\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = SingleTaskRoberta(num_labels=3).to(device)\ncriterion = nn.CrossEntropyLoss(ignore_index=-100)\n\nkf = KFold(n_splits=5, shuffle=True, random_state=42)\nall_fold_results = []\n\nfor fold, (train_ids, test_ids) in enumerate(kf.split(single_task_dataset)):\n    print(f\"\\nStarting Fold {fold + 1}\")\n\n    # Splitting the dataset into training and validation subsets\n    train_subset = Subset(single_task_dataset, train_ids)\n    val_size = int(0.1 * len(train_subset))  # For example, 10% for validation\n    train_size = len(train_subset) - val_size\n    train_dataset, val_dataset = random_split(train_subset, [train_size, val_size])\n    \n    train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n    val_dataloader = DataLoader(val_dataset, batch_size=8)  # Validation DataLoader\n    test_dataloader = DataLoader(Subset(single_task_dataset, test_ids), batch_size=8)\n\n \n    ############\n\n    model = SingleTaskRoberta(num_labels=3).to(device)\n\n    optimizer = AdamW(model.parameters(), lr=5e-5)\n\n\n\n    for epoch in range(num_epochs):  # Number of epochs\n        model.train()\n        total_loss, total_accuracy = 0, 0\n        for batch in tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}\"):\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['labels'].to(device)\n\n            optimizer.zero_grad()\n            logits = model(input_ids, attention_mask)\n\n            loss = criterion(logits.view(-1, num_labels), labels.view(-1))\n            loss.backward()\n            optimizer.step()\n            #scheduler.step()  # Update the learning rate\n           \n\n            total_loss += loss.item()\n            accuracy = calculate_accuracy(logits, labels)\n            total_accuracy += accuracy\n\n        epoch_loss = total_loss / len(train_dataloader)\n        epoch_accuracy = total_accuracy / len(train_dataloader)\n        print(f\"Training Loss: {epoch_loss:.4f}, Training Accuracy: {epoch_accuracy:.4f}\")\n\n        model.eval()\n        total_val_loss, total_val_accuracy = 0, 0\n        with torch.no_grad():\n            for batch in val_dataloader:\n                input_ids = batch['input_ids'].to(device)\n                attention_mask = batch['attention_mask'].to(device)\n                labels = batch['labels'].to(device)\n\n                logits = model(input_ids, attention_mask)\n                val_loss = criterion(logits.view(-1, num_labels), labels.view(-1))\n\n                total_val_loss += val_loss.item()\n                val_accuracy = calculate_accuracy(logits, labels)\n                total_val_accuracy += val_accuracy\n\n        \n        val_accuracy = total_val_accuracy / len(val_dataloader)\n        print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n\n        # Test phase for the current fold\n        test_preds, test_labels = [], []\n        model.eval()\n        with torch.no_grad():\n            for batch in test_dataloader:\n                input_ids = batch['input_ids'].to(device)\n                attention_mask = batch['attention_mask'].to(device)\n                labels = batch['labels'].to(device)\n\n                logits = model(input_ids, attention_mask)\n                preds = torch.argmax(logits, dim=-1).detach().cpu().numpy()\n                labels = labels.cpu().numpy()\n\n                # Filter out '-100' used for padding in labels\n                active = labels != -100\n                test_preds.extend(preds[active])\n                test_labels.extend(labels[active])\n\n    precision, recall, f1, _ = precision_recall_fscore_support(test_labels, test_preds, average='macro', zero_division=0)\n    print(f\"\\nFold {fold + 1} - Test Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}\")\n    \n    \n    all_fold_results.append({'precision': precision, 'recall': recall, 'f1': f1})\n    \n# Calculate and print average metrics after all folds\navg_precision = np.mean([fold['precision'] for fold in all_fold_results])\navg_recall = np.mean([fold['recall'] for fold in all_fold_results])\navg_f1 = np.mean([fold['f1'] for fold in all_fold_results])\n\nprint(f\"\\nAverage Across All Folds - Precision: {avg_precision:.4f}, Recall: {avg_recall:.4f}, F1: {avg_f1:.4f}\")\n\n","metadata":{"execution":{"iopub.status.busy":"2024-03-29T11:18:31.777097Z","iopub.execute_input":"2024-03-29T11:18:31.777518Z","iopub.status.idle":"2024-03-29T11:27:26.359593Z","shell.execute_reply.started":"2024-03-29T11:18:31.777484Z","shell.execute_reply":"2024-03-29T11:27:26.358433Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\nStarting Fold 1\n","output_type":"stream"},{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 1:   0%|          | 0/115 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"43891b0fdd39403f8203f34979034da3"}},"metadata":{}},{"name":"stdout","text":"Training Loss: 0.3014, Training Accuracy: 0.8990\nValidation Loss: 0.0746, Validation Accuracy: 0.9384\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 2:   0%|          | 0/115 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"67445bfc2d9940049b259540114013bf"}},"metadata":{}},{"name":"stdout","text":"Training Loss: 0.1716, Training Accuracy: 0.9399\nValidation Loss: 0.0398, Validation Accuracy: 0.9242\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 3:   0%|          | 0/115 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d08e11b7d5c740f09ff7f6077b7c8901"}},"metadata":{}},{"name":"stdout","text":"Training Loss: 0.1070, Training Accuracy: 0.9631\nValidation Loss: 0.0319, Validation Accuracy: 0.9647\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 4:   0%|          | 0/115 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"266b3a1519844eda9732ca04f2cca95a"}},"metadata":{}},{"name":"stdout","text":"Training Loss: 0.0847, Training Accuracy: 0.9717\nValidation Loss: 0.0056, Validation Accuracy: 0.9786\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 5:   0%|          | 0/115 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77f285e4afd040a0bd79c8c90565d27d"}},"metadata":{}},{"name":"stdout","text":"Training Loss: 0.0614, Training Accuracy: 0.9781\nValidation Loss: 0.0021, Validation Accuracy: 0.9808\n\nFold 1 - Test Precision: 0.9646, Recall: 0.9687, F1: 0.9666\n\nStarting Fold 2\n","output_type":"stream"},{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 1:   0%|          | 0/115 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c87d9776d0647db9c3dd01362a0d306"}},"metadata":{}},{"name":"stdout","text":"Training Loss: 0.2857, Training Accuracy: 0.9027\nValidation Loss: 0.2253, Validation Accuracy: 0.9319\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 2:   0%|          | 0/115 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18e786252f114fab85a70e5e484aa4aa"}},"metadata":{}},{"name":"stdout","text":"Training Loss: 0.1608, Training Accuracy: 0.9450\nValidation Loss: 0.1610, Validation Accuracy: 0.9607\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 3:   0%|          | 0/115 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77a8f57716b0493e81cbad4355f5fee1"}},"metadata":{}},{"name":"stdout","text":"Training Loss: 0.1135, Training Accuracy: 0.9624\nValidation Loss: 0.1445, Validation Accuracy: 0.9700\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 4:   0%|          | 0/115 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77b737c382a646dcbdd1c8632b7364f7"}},"metadata":{}},{"name":"stdout","text":"Training Loss: 0.0708, Training Accuracy: 0.9769\nValidation Loss: 0.0838, Validation Accuracy: 0.9732\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 5:   0%|          | 0/115 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8077945a45124ab7aab38ef32662c836"}},"metadata":{}},{"name":"stdout","text":"Training Loss: 0.0646, Training Accuracy: 0.9775\nValidation Loss: 0.0811, Validation Accuracy: 0.9752\n\nFold 2 - Test Precision: 0.9539, Recall: 0.9599, F1: 0.9569\n\nStarting Fold 3\n","output_type":"stream"},{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 1:   0%|          | 0/115 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36f1312083214022bec26ae6cd7637b4"}},"metadata":{}},{"name":"stdout","text":"Training Loss: 0.2959, Training Accuracy: 0.9034\nValidation Loss: 0.1628, Validation Accuracy: 0.9397\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 2:   0%|          | 0/115 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d667a4d5074746e5947f9b9b3ce1cb25"}},"metadata":{}},{"name":"stdout","text":"Training Loss: 0.1726, Training Accuracy: 0.9407\nValidation Loss: 0.1191, Validation Accuracy: 0.9362\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 3:   0%|          | 0/115 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"89fb2ebbfe224b3db9d6a50ec18b324c"}},"metadata":{}},{"name":"stdout","text":"Training Loss: 0.1173, Training Accuracy: 0.9605\nValidation Loss: 0.0841, Validation Accuracy: 0.9776\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 4:   0%|          | 0/115 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e331ee006e824b468e9ca1260563433c"}},"metadata":{}},{"name":"stdout","text":"Training Loss: 0.0775, Training Accuracy: 0.9749\nValidation Loss: 0.0564, Validation Accuracy: 0.9708\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 5:   0%|          | 0/115 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b769abd1378455997b5f0ff5629f92f"}},"metadata":{}},{"name":"stdout","text":"Training Loss: 0.0624, Training Accuracy: 0.9800\nValidation Loss: 0.0450, Validation Accuracy: 0.9790\n\nFold 3 - Test Precision: 0.9535, Recall: 0.9697, F1: 0.9614\n\nStarting Fold 4\n","output_type":"stream"},{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 1:   0%|          | 0/115 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"19fda2d3e78f41058e48d8a30c0d7a84"}},"metadata":{}},{"name":"stdout","text":"Training Loss: 0.3056, Training Accuracy: 0.8922\nValidation Loss: 0.0643, Validation Accuracy: 0.9328\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 2:   0%|          | 0/115 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"03c7e4f2129a40e7b23886fb2b7353e9"}},"metadata":{}},{"name":"stdout","text":"Training Loss: 0.1595, Training Accuracy: 0.9461\nValidation Loss: 0.0154, Validation Accuracy: 0.9607\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 3:   0%|          | 0/115 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fdbfdc12a9ec42edb463312bb45476ae"}},"metadata":{}},{"name":"stdout","text":"Training Loss: 0.1002, Training Accuracy: 0.9658\nValidation Loss: 0.0241, Validation Accuracy: 0.9590\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 4:   0%|          | 0/115 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00a4b148da5447ebae3020cad65d3315"}},"metadata":{}},{"name":"stdout","text":"Training Loss: 0.0867, Training Accuracy: 0.9721\nValidation Loss: 0.0179, Validation Accuracy: 0.9730\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 5:   0%|          | 0/115 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af62bfe2286544e88900d79236e6413b"}},"metadata":{}},{"name":"stdout","text":"Training Loss: 0.0632, Training Accuracy: 0.9799\nValidation Loss: 0.0022, Validation Accuracy: 0.9679\n\nFold 4 - Test Precision: 0.9463, Recall: 0.9615, F1: 0.9537\n\nStarting Fold 5\n","output_type":"stream"},{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 1:   0%|          | 0/115 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e18fbdd296fc44838ab2082e33104217"}},"metadata":{}},{"name":"stdout","text":"Training Loss: 0.3023, Training Accuracy: 0.8928\nValidation Loss: 0.1886, Validation Accuracy: 0.9362\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 2:   0%|          | 0/115 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"875ad19f80b94344b72649032bbf8bd9"}},"metadata":{}},{"name":"stdout","text":"Training Loss: 0.1650, Training Accuracy: 0.9459\nValidation Loss: 0.1266, Validation Accuracy: 0.9519\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 3:   0%|          | 0/115 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c0f6fb664ff4275a9c8fc8d1781dd3f"}},"metadata":{}},{"name":"stdout","text":"Training Loss: 0.1215, Training Accuracy: 0.9618\nValidation Loss: 0.2104, Validation Accuracy: 0.9578\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 4:   0%|          | 0/115 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f03c4b5ea934898b761ee4d5ffc360d"}},"metadata":{}},{"name":"stdout","text":"Training Loss: 0.0874, Training Accuracy: 0.9701\nValidation Loss: 0.0233, Validation Accuracy: 0.9798\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 5:   0%|          | 0/115 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ceccde5497c4ea4ae8d5c2be88f0e87"}},"metadata":{}},{"name":"stdout","text":"Training Loss: 0.0755, Training Accuracy: 0.9748\nValidation Loss: 0.0483, Validation Accuracy: 0.9787\n\nFold 5 - Test Precision: 0.9610, Recall: 0.9646, F1: 0.9627\n\nAverage Across All Folds - Precision: 0.9559, Recall: 0.9649, F1: 0.9603\n","output_type":"stream"}]}]}