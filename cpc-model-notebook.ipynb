{"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6939736,"sourceType":"datasetVersion","datasetId":3985377},{"sourceId":6982985,"sourceType":"datasetVersion","datasetId":4013207}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"papermill":{"default_parameters":{},"duration":5.733813,"end_time":"2023-11-16T17:36:14.129927","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2023-11-16T17:36:08.396114","version":"2.4.0"},"colab":{"provenance":[]}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Introduction to Comparative Preference Classification (CPC)\n\nComparative Preference Classification (CPC) emerges as a crucial phase in analyzing comparative relations, focusing on discerning preferences between entities based on a set of attributes. Employing the RoBERTa-pair-NLI-M model, CPC is treated as a sentence-pair classification challenge, enriching the model's understanding by incorporating auxiliary sentences. This task is pivotal in extracting nuanced comparative insights from text, categorizing preferences into 14 distinct classes and enhancing the comprehension of comparative dynamics within questions. As a vital component of the pipeline, CPC leverages advanced NLP techniques to refine the analysis of comparative relations, underscoring the sophisticated capabilities of the RoBERTa model in handling complex classification tasks.\n","metadata":{}},{"cell_type":"markdown","source":"## Data Retrieval and Extraction\n\nUtilizing the `requests` library, this code snippet handles the downloading of a dataset from a specified URL and subsequently unzips the contents using the `zipfile` module. This step is essential for acquiring the necessary data for our Comparative Preference Classification (CPC) analysis, ensuring we have the foundational datasets ready for preprocessing and further examination.\n\n","metadata":{}},{"cell_type":"code","source":"import requests\nimport zipfile\nimport os\n\ndata_url = \"https://github.com/mahsamb/SCRQD/raw/main/Dataset.zip\"\nzip_filename = \"Dataset.zip\"\n\n# Downloading using requests\nresponse = requests.get(data_url)\n\n# Check if the request was successful (status_code 200)\nif response.status_code == 200:\n    with open(zip_filename, \"wb\") as f:\n        f.write(response.content)\nelse:\n    print(f\"Failed to retrieve the data: {response.status_code}: {response.text}\")\n    # Add additional error handling here\n\n# Unzipping the dataset\ntry:\n    with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n        zip_ref.extractall(\"data\")\n    print(\"Files extracted:\")\n    print(os.listdir(\"data\"))\nexcept zipfile.BadZipFile:\n    print(\"Error: The file doesn’t appear to be a valid zip file\")","metadata":{"id":"hQtEzBjrGKjj","outputId":"d8f38a5e-e285-4f07-fede-b0ca2dca3fa6","execution":{"iopub.status.busy":"2024-03-25T11:46:30.694305Z","iopub.execute_input":"2024-03-25T11:46:30.694694Z","iopub.status.idle":"2024-03-25T11:46:31.147551Z","shell.execute_reply.started":"2024-03-25T11:46:30.694662Z","shell.execute_reply":"2024-03-25T11:46:31.146507Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Files extracted:\n['Relations.pkl', 'Questions.pkl', 'EntityRoles.pkl', 'Elements.pkl', 'ComparativePreferences.pkl']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Loading and Preparing Data\n\nBy importing essential libraries such as `numpy`, `pandas`, and `pickle`, this section of code focuses on loading the comparative preferences and questions from serialized `.pkl` files into Python dictionaries. This crucial step prepares our dataset for the CPC task, allowing for the manipulation and analysis of the data within a structured format conducive to our subsequent NLP tasks.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pickle as cPickle\nimport pickle\nimport re\nimport pandas as pd\nfrom IPython.display import display, HTML\nimport random\n\n\n\nwith open(r\"/kaggle/working/data/Questions.pkl\", \"rb\") as input_file:\n    QuestionDict = pickle.load(input_file)\n    input_file.close()\n\n\nwith open(r\"/kaggle/working/data/ComparativePreferences.pkl\", \"rb\") as input_file:\n    CPCDict = pickle.load(input_file)\n    input_file.close()","metadata":{"papermill":{"duration":0.526316,"end_time":"2023-11-16T17:36:12.801063","exception":false,"start_time":"2023-11-16T17:36:12.274747","status":"completed"},"tags":[],"id":"fJSN_w3-GKjl","execution":{"iopub.status.busy":"2024-03-25T11:46:31.149403Z","iopub.execute_input":"2024-03-25T11:46:31.150314Z","iopub.status.idle":"2024-03-25T11:46:32.889531Z","shell.execute_reply.started":"2024-03-25T11:46:31.150276Z","shell.execute_reply":"2024-03-25T11:46:32.888624Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"The table above shows an example sentence annotated with our enhanced BIO scheme. Each token (word) from the sentence is classified according to whether it signifies the beginning (B), inside (I), or outside (O) of the three categories: Entity (E), Aspect (A), and Constraint (C).\n","metadata":{"papermill":{"duration":0.009964,"end_time":"2023-11-16T17:36:13.184907","exception":false,"start_time":"2023-11-16T17:36:13.174943","status":"completed"},"tags":[],"id":"HnP07t35GKjq"}},{"cell_type":"markdown","source":"## Comparative Preference Classification (CPC)\n\n### Overview of the CPC Task\nThe Comparative Preference Classification (CPC) task is a pivotal component of our study in understanding subjective comparative questions. This task involves classifying the nature of preferences expressed in comparative questions, such as determining whether a subjective comparison implies a preference for one entity over another.\n\nNext, we will dive into a detailed exploration of this table, examining sample entries and their classifications to understand better how preferences are articulated and categorized in our dataset.","metadata":{"papermill":{"duration":0.012468,"end_time":"2023-11-16T17:36:13.427977","exception":false,"start_time":"2023-11-16T17:36:13.415509","status":"completed"},"tags":[],"id":"iSsyd78UGKjq"}},{"cell_type":"markdown","source":"## Data Exploration and Example Selection\n\nThis code snippet demonstrates the process of randomly sampling entries from the Comparative Preference Classification (CPC) dataset to illustrate the variety and complexity of the data. By selecting a subset of keys and extracting corresponding questions, pseudo-sentences, and preference types, we construct a DataFrame that showcases examples of the data we'll be analyzing. This exploratory step is pivotal for understanding the dataset's structure and the nature of the comparative preferences, facilitating a deeper insight into the challenges and nuances of the CPC task.","metadata":{}},{"cell_type":"code","source":"# Sample 10 keys from the dictionary\nrandom_keys = random.sample(list(CPCDict.keys()), 10)\n\n# Build the example_data structure based on the sampled keys\nexample_data = {\n    'ID': [],\n    'Question': [],\n    'Pseudo-Sentence': [],\n    'Preference Type': []\n\n}\n\n# Loop through the sampled keys to retrieve entries\nfor key in random_keys:\n    question = QuestionDict.get(key, 'not found')\n    entry = CPCDict[key]\n    example_data['ID'].append(key)\n    example_data['Question'].append(question)\n    example_data['Pseudo-Sentence'].append(entry[0][0])\n    example_data['Preference Type'].append(entry[0][1])\n\n\n# Create a DataFrame\ndf_examples = pd.DataFrame(example_data)\n\n# Function to format the display of lists within the DataFrame\ndef format_list_for_display(series):\n    return series.apply(lambda x: ', '.join(x) if isinstance(x, list) else x)\n\n# Apply formatting function to the DataFrame\ndf_examples['Question'] = format_list_for_display(df_examples['Question'])\ndf_examples['Pseudo-Sentence'] = format_list_for_display(df_examples['Pseudo-Sentence'])\ndf_examples['Preference Type'] = format_list_for_display(df_examples['Preference Type'])\n\n\n# Display the DataFrame\ndisplay(HTML(df_examples.to_html(index=False)))\n","metadata":{"papermill":{"duration":0.034288,"end_time":"2023-11-16T17:36:13.475067","exception":false,"start_time":"2023-11-16T17:36:13.440779","status":"completed"},"tags":[],"id":"mlVnqmfhGKjq","outputId":"8c3351e6-41e7-410d-960b-c3a076a4822a","execution":{"iopub.status.busy":"2024-03-25T11:46:32.890916Z","iopub.execute_input":"2024-03-25T11:46:32.891451Z","iopub.status.idle":"2024-03-25T11:46:32.918199Z","shell.execute_reply.started":"2024-03-25T11:46:32.891414Z","shell.execute_reply":"2024-03-25T11:46:32.917211Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>ID</th>\n      <th>Question</th>\n      <th>Pseudo-Sentence</th>\n      <th>Preference Type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>36</td>\n      <td>Would you prefer to buy the Motorola Moto X or the LG Optimus G Pro ?</td>\n      <td>Motorola Moto X versus LG Optimus G Pro</td>\n      <td>XorB</td>\n    </tr>\n    <tr>\n      <td>107</td>\n      <td>Overall , in terms of service , are Samsung phones better than OnePlus in India ?</td>\n      <td>Samsung phones service versus OnePlus service</td>\n      <td>B</td>\n    </tr>\n    <tr>\n      <td>786</td>\n      <td>Why is my Samsung Galaxy S 4 better than a Samsung Galaxy S 5 in the AnTuTu benchmark ?</td>\n      <td>Samsung Galaxy S4 versus Samsung Galaxy S5</td>\n      <td>B</td>\n    </tr>\n    <tr>\n      <td>356</td>\n      <td>Which one is better in terms of optics , the Huawei P 40 Pro or the Samsung S 20 Ultra ?</td>\n      <td>Huawei P40 Pro optics versus Samsung S20 Ultra optics</td>\n      <td>XorB</td>\n    </tr>\n    <tr>\n      <td>982</td>\n      <td>I wanted to buy an smartphone , but I am in a dilemma between iPhone 7 or iPhone 7 Plus . Should I buy an iPhone 7 with 128 GB memory or a 7 Plus with 32 GB memory ? They were the same price .</td>\n      <td>iPhone 7 versus iPhone 7 Plus</td>\n      <td>XorB</td>\n    </tr>\n    <tr>\n      <td>941</td>\n      <td>Why do Samsung phones have low specs and poor performance , unlike the Chinese brands ?</td>\n      <td>Samsung phones specs versus Chinese brands specs</td>\n      <td>W</td>\n    </tr>\n    <tr>\n      <td>1097</td>\n      <td>Which phone is the most undesirable between the Samsung J 3 and the Honor 7 s ?</td>\n      <td>Samsung J3 versus Honor 7s</td>\n      <td>XorSW</td>\n    </tr>\n    <tr>\n      <td>57</td>\n      <td>Which smartphone has the most user - friendly interface between a Samsung Galaxy Note 10 and a Note 9 ?</td>\n      <td>Samsung Galaxy Note 10 interface and Note 9 interface versus All interface</td>\n      <td>SB</td>\n    </tr>\n    <tr>\n      <td>41</td>\n      <td>Which is the best smartphone with good noise cancellation and sound quality ?</td>\n      <td>X noise cancellation versus All noise cancellation</td>\n      <td>SB</td>\n    </tr>\n    <tr>\n      <td>299</td>\n      <td>Which phone is preferable between the iPhone 6 S and the Samsung J 4 + ?</td>\n      <td>iPhone 6S versus Samsung J4+</td>\n      <td>XorB</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}}]},{"cell_type":"markdown","source":"### Utilizing NLI-M for Pseudo-Sentence Generation\nTo facilitate the CPC task, we adopt Natural Language Inference with Multiple Output (NLI-M). This approach involves generating pseudo-sentences that represent the core comparison in each question.\n\n- **Pseudo-Sentence Formation**: We create pseudo-sentences by pairing entities and aspects mentioned in the question. For instance, a comparison between two products based on a specific aspect is represented as \"(entity i-aspect j versus entity z-aspect k)\". In cases where a question lacks explicit mention of an entity or aspect, we use placeholders:\n  - \"X\" is used when an entity is not specified.\n  - \"All\" is used for unspecified aspects.\n- **Example**: Given a question comparing the camera quality of 'iPhone 10' and 'iPhone XS', the corresponding pseudo-sentence would be \"iPhone 10-camera versus iPhone XS-camera\".\n\nThis method allows us to convert complex comparative questions into a format that is more readily analyzable by our classification models.\n","metadata":{"papermill":{"duration":0.01309,"end_time":"2023-11-16T17:36:13.501695","exception":false,"start_time":"2023-11-16T17:36:13.488605","status":"completed"},"tags":[],"id":"W8boLV5mGKjq"}},{"cell_type":"markdown","source":"### Comparative Preference Categories\nWe have outlined 14 potential preference categories for subjective comparative questions: `B`, `SB`, `W`, `SW`, `E`, `XOR-B`, `XOR-SB`, `XOE-E`, `XOR-W`, `XOR-SW`, `X`, `X-SB`, `X-SW`, `Non-Grad`. Consequently, the output label for the CPC task will fall into one of these 14 classifications. A detailed explanation of these abbreviations, along with their expanded interpretations, is encapsulated as :\n\n\n| Preference Type | Description      |\n|-----------------|------------------|\n| B               | Better           |\n| SB              | Strong Better    |\n| E               | Equal            |\n| W               | Worse            |\n| SW              | Strong Worse     |\n| XOR-B           | XOR-Better       |\n| XOR-SB          | XOR-Strong Better|\n| XOR-E           | XOR-Equal        |\n| XOR-W           | XOR-Worse        |\n| XOR-SW          | XOR-Strong Worse |\n| X-SB            | X-Strong Better  |\n| _X               | X                |\n| X-SW            | X-Strong Worse   |\n| Non-Grad        | Non-Gradable     |\n","metadata":{"papermill":{"duration":0.013244,"end_time":"2023-11-16T17:36:13.529591","exception":false,"start_time":"2023-11-16T17:36:13.516347","status":"completed"},"tags":[],"id":"_YLHGenCGKjq"}},{"cell_type":"markdown","source":"## Comprehensive Data Compilation for CPC\n\nIn this segment, we systematically compile a comprehensive dataset from all available entries in the Comparative Preference Classification (CPC) dictionary, as opposed to randomly sampling a subset. By iterating over each key, we gather corresponding questions, pseudo-sentences, and preference types, thus forming a detailed DataFrame. This approach ensures a thorough overview of the entire dataset, offering insights into the full spectrum of comparative preferences present. This methodical compilation is instrumental for in-depth analysis and modeling, providing a solid foundation for exploring the nuances and patterns within the CPC task.","metadata":{}},{"cell_type":"code","source":"# Sample 10 keys from the dictionary\nCPC_keys = list(CPCDict.keys())\n\n# Build the example_data structure based on the sampled keys\nexample_data = {\n    'ID': [],\n    'Question': [],\n    'Pseudo-Sentence': [],\n    'Preference Type': []\n\n}\n\n# Loop through the sampled keys to retrieve entries\nfor key in CPC_keys:\n    question = QuestionDict.get(key, 'not found')\n    entry = CPCDict[key]\n    example_data['ID'].append(key)\n    example_data['Question'].append(question)\n    example_data['Pseudo-Sentence'].append(entry[0][0])\n    example_data['Preference Type'].append(entry[0][1])\n\n\n# Create a DataFrame\ndf_examples = pd.DataFrame(example_data)\n\nprint(df_examples)","metadata":{"execution":{"iopub.status.busy":"2024-03-25T11:46:32.920440Z","iopub.execute_input":"2024-03-25T11:46:32.920731Z","iopub.status.idle":"2024-03-25T11:46:32.941952Z","shell.execute_reply.started":"2024-03-25T11:46:32.920706Z","shell.execute_reply":"2024-03-25T11:46:32.941056Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"        ID                                           Question  \\\n0        1  What are the best smartphones with a built in ...   \n1        2  Is the OnePlus 8 T appearance similar to the O...   \n2        3  Does OnePlus 6 has been able to beat its ZenFo...   \n3        4  Samsung Galaxy M 32 , Realme Narzo 30 , or Viv...   \n4        5  Why is the Samsung Galaxy J 3 phone so awkward...   \n...    ...                                                ...   \n1270  1271  how awful is the user experience of the iPhone...   \n1271  1272  How bad is the resolution of the Asus Zenfone ...   \n1272  1273  How bad is the image quality of the Apple iPho...   \n1273  1274  How much do you think the LG G 6 performance i...   \n1274  1275  How bad is the iPhone 13 mini battery than iPh...   \n\n                                        Pseudo-Sentence Preference Type  \n0                          X display versus All display              SB  \n1     OnePlus 8T appearance versus OnePlus 7T phone ...               E  \n2                           OnePlus 6 versus ZenFone 5Z              SB  \n3     Samsung Galaxy M32 and Realme Narzo 30 and Viv...         NonGrad  \n4        Samsung Galaxy J3V phone versus iPhone 13 mini              SW  \n...                                                 ...             ...  \n1270  iPhone 6 playing music versus Google Pixel 4a ...            SW_X  \n1271  Asus Zenfone 8 resolution versus Sony Xperia Z...            SW_X  \n1272  Apple iPhone 6s image quality versus Samsung G...            SW_X  \n1273      LG G6 performance versus Honor 6X performance            SW_X  \n1274    iPhone 13 mini battery versus iPhone 13 battery            SW_X  \n\n[1275 rows x 4 columns]\n","output_type":"stream"}]},{"cell_type":"code","source":"#print(j)","metadata":{"execution":{"iopub.status.busy":"2024-03-25T11:46:32.942912Z","iopub.execute_input":"2024-03-25T11:46:32.943178Z","iopub.status.idle":"2024-03-25T11:46:32.950123Z","shell.execute_reply.started":"2024-03-25T11:46:32.943156Z","shell.execute_reply":"2024-03-25T11:46:32.949126Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"!pip install adapters","metadata":{"execution":{"iopub.status.busy":"2024-03-25T11:46:32.951406Z","iopub.execute_input":"2024-03-25T11:46:32.952034Z","iopub.status.idle":"2024-03-25T11:47:01.660944Z","shell.execute_reply.started":"2024-03-25T11:46:32.952008Z","shell.execute_reply":"2024-03-25T11:47:01.659857Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Collecting adapters\n  Downloading adapters-0.1.2-py3-none-any.whl.metadata (15 kB)\nCollecting transformers~=4.36.0 (from adapters)\n  Downloading transformers-4.36.2-py3-none-any.whl.metadata (126 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.8/126.8 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers~=4.36.0->adapters) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers~=4.36.0->adapters) (0.21.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers~=4.36.0->adapters) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers~=4.36.0->adapters) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers~=4.36.0->adapters) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers~=4.36.0->adapters) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers~=4.36.0->adapters) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers~=4.36.0->adapters) (0.15.2)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers~=4.36.0->adapters) (0.4.2)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers~=4.36.0->adapters) (4.66.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers~=4.36.0->adapters) (2024.3.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers~=4.36.0->adapters) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers~=4.36.0->adapters) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers~=4.36.0->adapters) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers~=4.36.0->adapters) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers~=4.36.0->adapters) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers~=4.36.0->adapters) (2024.2.2)\nDownloading adapters-0.1.2-py3-none-any.whl (256 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m256.0/256.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading transformers-4.36.2-py3-none-any.whl (8.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: transformers, adapters\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.38.2\n    Uninstalling transformers-4.38.2:\n      Successfully uninstalled transformers-4.38.2\nSuccessfully installed adapters-0.1.2 transformers-4.36.2\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Training and Evaluating the Comparative Preference Classification Model\n\nThis comprehensive code block orchestrates the training and evaluation of a Comparative Preference Classification (CPC) model using the RoBERTa architecture. Initially, it transforms preference types into numeric labels to facilitate model processing. Leveraging a `StratifiedKFold` strategy, the dataset is divided into training and testing sets across multiple folds to ensure a thorough evaluation. A custom `Dataset` class prepares sentence pairs for RoBERTa, incorporating both questions and pseudo-sentences as inputs. Throughout the training phases, the model optimizes its parameters to discern the subtle distinctions among various preference types. Finally, after training across all folds, precision, recall, and F1-score metrics are calculated, providing a detailed insight into the model's performance. The use of a classification report and confusion matrix offers a granular view of how well the model distinguishes between the nuanced categories of comparative preferences.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import StratifiedKFold\nfrom transformers import RobertaTokenizer, RobertaForSequenceClassification\nfrom torch.optim import Adam,AdamW\nfrom torch.utils.data import Dataset, DataLoader\nimport torch\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report, confusion_matrix\nimport torch.nn.functional as F\nfrom tqdm.auto import tqdm\nimport adapters \nimport torch.nn as nn\nfrom transformers import RobertaModel, RobertaConfig, RobertaTokenizer\n\n\nclass CustomRobertaForSentencePairClassification(nn.Module):\n    def __init__(self, num_labels, device):\n        super(CustomRobertaForSentencePairClassification, self).__init__()\n        self.device = device\n        self.num_labels = num_labels  # Define num_labels as an attribute\n        config = RobertaConfig.from_pretrained('roberta-base', num_labels=num_labels)\n        self.roberta = RobertaModel.from_pretrained('roberta-base', config=config)\n        \n\n        \n        self.classifier = nn.Linear(config.hidden_size, num_labels)\n\n\n\n    def forward(self, input_ids, attention_mask, labels=None):\n        outputs = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n        sequence_output = outputs.last_hidden_state[:, 0, :]  # Use the [CLS] token's representation\n        logits = self.classifier(sequence_output)\n\n        loss = None\n        if labels is not None:\n            loss_fct = nn.CrossEntropyLoss()\n            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n        \n        return logits if loss is None else (loss, logits)\n\n# Example usage\nnum_labels = 14 # Define the number of labels for your classification task\n\n\n\n\n# Convert labels to integer IDs\nlabel_to_id = {label: idx for idx, label in enumerate(sorted(df_examples['Preference Type'].unique()))}\ndf_examples['label'] = df_examples['Preference Type'].map(label_to_id)\n\nclass SentencePairDataset(Dataset):\n    def __init__(self, questions, pseudo_sentences, labels, tokenizer, max_length=512):\n        self.questions = questions\n        self.pseudo_sentences = pseudo_sentences\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n\n    def __len__(self):\n        return len(self.questions)\n\n    def __getitem__(self, idx):\n        question = self.questions[idx]\n        pseudo_sentence = self.pseudo_sentences[idx]\n        label = self.labels[idx]\n\n        encoding = self.tokenizer.encode_plus(\n            question,\n            pseudo_sentence,\n            add_special_tokens=True,\n            max_length=self.max_length,\n            return_token_type_ids=False,\n            padding='max_length',\n            truncation=True,\n            return_attention_mask=True,\n            return_tensors='pt',\n        )\n\n        return {\n            'input_ids': encoding['input_ids'].flatten(),\n            'attention_mask': encoding['attention_mask'].flatten(),\n            'labels': torch.tensor(label, dtype=torch.long)\n        }\n\ntokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n\nstrat_kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\noverall_true_labels = []\noverall_predictions = []\n\nfor fold, (train_index, test_index) in enumerate(strat_kf.split(df_examples, df_examples['label'])):\n    print(f\"\\nStarting fold {fold+1}/{strat_kf.n_splits}\")\n\n    train_df = df_examples.iloc[train_index]\n    test_df = df_examples.iloc[test_index]\n\n    train_dataset = SentencePairDataset(\n        questions=train_df['Question'].tolist(),\n        pseudo_sentences=train_df['Pseudo-Sentence'].tolist(),\n        labels=train_df['label'].tolist(),\n        tokenizer=tokenizer\n    )\n\n    test_dataset = SentencePairDataset(\n        questions=test_df['Question'].tolist(),\n        pseudo_sentences=test_df['Pseudo-Sentence'].tolist(),\n        labels=test_df['label'].tolist(),\n        tokenizer=tokenizer\n    )\n\n    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n    test_loader = DataLoader(test_dataset, batch_size=8)\n\n\n\n    \n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model = CustomRobertaForSentencePairClassification(num_labels=num_labels, device=device)\n    model.to(device)\n\n    optimizer = Adam(model.parameters(), lr=3e-5)\n\n    \n\n\n    for epoch in range(5):  # Adjust the number of epochs if necessary\n        model.train()\n        print(f\"\\nTraining Fold {fold+1}, Epoch {epoch+1}\")\n        for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n            batch = {k: v.to(device) for k, v in batch.items()}\n            optimizer.zero_grad()\n\n            # Correctly handle the model's output\n            output = model(**batch)\n            # Check if the output is a tuple (which includes loss and logits)\n            if isinstance(output, tuple):\n                loss = output[0]  # Extract the loss from the tuple\n            else:\n                # Directly use output as loss if it's not a tuple (logits only, no labels provided)\n                loss = output\n\n            loss.backward()\n            optimizer.step()\n\n    # Evaluation\n    model.eval()\n    true_labels, predictions = [], []\n\n\n    with torch.no_grad():\n        for batch in tqdm(test_loader, desc=f\"Evaluating Fold {fold+1}\"):\n            batch = {k: v.to(model.device) for k, v in batch.items()}\n            outputs = model(**batch)\n            # Check if the output is a tuple and unpack accordingly\n            if isinstance(outputs, tuple):\n                logits = outputs[1]  # logits are the second element in the tuple\n            else:\n                logits = outputs\n            preds = torch.argmax(F.softmax(logits, dim=1), dim=1).cpu().numpy()\n            labels = batch['labels'].cpu().numpy()\n            true_labels.extend(labels)\n            predictions.extend(preds)\n\n\n    # Store for overall evaluation\n    overall_true_labels.extend(true_labels)\n    overall_predictions.extend(predictions)\n    \n    # Compute and display precision, recall, and F1-score for the current fold\n    precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predictions, average='macro')\n    print(f\"\\nFold {fold+1} Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1:.4f}\")\n\n# After all folds are processed, calculate overall metrics and display the classification report\nprint(\"\\n\\nOverall Classification Report:\")\nprint(classification_report(overall_true_labels, overall_predictions, target_names=label_to_id.keys(), digits=4))\nprint(\"Overall Confusion Matrix:\")\nprint(confusion_matrix(overall_true_labels, overall_predictions))\n","metadata":{"execution":{"iopub.status.busy":"2024-03-25T11:48:08.151226Z","iopub.execute_input":"2024-03-25T11:48:08.151607Z","iopub.status.idle":"2024-03-25T12:26:13.640730Z","shell.execute_reply.started":"2024-03-25T11:48:08.151566Z","shell.execute_reply":"2024-03-25T12:26:13.639643Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"\nStarting fold 1/5\n","output_type":"stream"},{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\nTraining Fold 1, Epoch 1\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 1:   0%|          | 0/128 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"04f51ff912fa435784dda65c67266090"}},"metadata":{}},{"name":"stdout","text":"\nTraining Fold 1, Epoch 2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 2:   0%|          | 0/128 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6ce3e87bc1b49eca6a8f1dfdc39ce54"}},"metadata":{}},{"name":"stdout","text":"\nTraining Fold 1, Epoch 3\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 3:   0%|          | 0/128 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"78f908c8d5e54df094d10dd72504d222"}},"metadata":{}},{"name":"stdout","text":"\nTraining Fold 1, Epoch 4\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 4:   0%|          | 0/128 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad87348473254192b852661564708dc9"}},"metadata":{}},{"name":"stdout","text":"\nTraining Fold 1, Epoch 5\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 5:   0%|          | 0/128 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4dcd72504f75480caa0825f02c53d41f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Fold 1:   0%|          | 0/32 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f8035f7d3394737b305e058f9ddf49b"}},"metadata":{}},{"name":"stdout","text":"\nFold 1 Precision: 0.8714, Recall: 0.8306, F1-Score: 0.8407\n\nStarting fold 2/5\n","output_type":"stream"},{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\nTraining Fold 2, Epoch 1\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 1:   0%|          | 0/128 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"636469db88c14fe69a2864d081a116f6"}},"metadata":{}},{"name":"stdout","text":"\nTraining Fold 2, Epoch 2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 2:   0%|          | 0/128 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e7a33fa6fa64f36b1725912ea4fa84e"}},"metadata":{}},{"name":"stdout","text":"\nTraining Fold 2, Epoch 3\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 3:   0%|          | 0/128 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c84a366dfd4f4e6bbf3948f03c98ff9f"}},"metadata":{}},{"name":"stdout","text":"\nTraining Fold 2, Epoch 4\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 4:   0%|          | 0/128 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"922143205b26447fb772a01084ae1836"}},"metadata":{}},{"name":"stdout","text":"\nTraining Fold 2, Epoch 5\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 5:   0%|          | 0/128 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13d1f4ad89aa452280b8f089f2a25dd1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Fold 2:   0%|          | 0/32 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a99580622322438e89cb91d5b343e0ed"}},"metadata":{}},{"name":"stdout","text":"\nFold 2 Precision: 0.8616, Recall: 0.8340, F1-Score: 0.8411\n\nStarting fold 3/5\n","output_type":"stream"},{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\nTraining Fold 3, Epoch 1\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 1:   0%|          | 0/128 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"795eb03764194eb58d1233bbac03ca90"}},"metadata":{}},{"name":"stdout","text":"\nTraining Fold 3, Epoch 2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 2:   0%|          | 0/128 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9fd76d41a45c4a5c88d4a8b56853c545"}},"metadata":{}},{"name":"stdout","text":"\nTraining Fold 3, Epoch 3\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 3:   0%|          | 0/128 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb06cb79a6414c048f9cd714ed1ac21e"}},"metadata":{}},{"name":"stdout","text":"\nTraining Fold 3, Epoch 4\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 4:   0%|          | 0/128 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b670944d07e45b88d3c320b5453666b"}},"metadata":{}},{"name":"stdout","text":"\nTraining Fold 3, Epoch 5\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 5:   0%|          | 0/128 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e7129ecbbc1e4fb89e477f9a97853312"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Fold 3:   0%|          | 0/32 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d7ec716d94e64b6dafe395640b6a8103"}},"metadata":{}},{"name":"stdout","text":"\nFold 3 Precision: 0.8488, Recall: 0.8514, F1-Score: 0.8398\n\nStarting fold 4/5\n","output_type":"stream"},{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\nTraining Fold 4, Epoch 1\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 1:   0%|          | 0/128 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0500f45d2a524324982c2c53ed0beebe"}},"metadata":{}},{"name":"stdout","text":"\nTraining Fold 4, Epoch 2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 2:   0%|          | 0/128 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a68c279021f46bbb356d140f07b719c"}},"metadata":{}},{"name":"stdout","text":"\nTraining Fold 4, Epoch 3\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 3:   0%|          | 0/128 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"31b7c757a6ca4159b796e5e2a4fe0fbc"}},"metadata":{}},{"name":"stdout","text":"\nTraining Fold 4, Epoch 4\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 4:   0%|          | 0/128 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8fc9321eb0024aad848cfd1ee625ed67"}},"metadata":{}},{"name":"stdout","text":"\nTraining Fold 4, Epoch 5\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 5:   0%|          | 0/128 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cbfb0dace71046c7b5f871aaa62a848a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Fold 4:   0%|          | 0/32 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dd4055cc216744689afed7f1817d1111"}},"metadata":{}},{"name":"stdout","text":"\nFold 4 Precision: 0.8756, Recall: 0.8558, F1-Score: 0.8604\n\nStarting fold 5/5\n","output_type":"stream"},{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\nTraining Fold 5, Epoch 1\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 1:   0%|          | 0/128 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"117bf2934f7546f2831ea113f16f3bc7"}},"metadata":{}},{"name":"stdout","text":"\nTraining Fold 5, Epoch 2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 2:   0%|          | 0/128 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"37577a7884bf4c55804920060f7316e8"}},"metadata":{}},{"name":"stdout","text":"\nTraining Fold 5, Epoch 3\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 3:   0%|          | 0/128 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6185512d4f9247569e1687b008655338"}},"metadata":{}},{"name":"stdout","text":"\nTraining Fold 5, Epoch 4\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 4:   0%|          | 0/128 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1546e7974bc5425e85b3243a1102118d"}},"metadata":{}},{"name":"stdout","text":"\nTraining Fold 5, Epoch 5\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 5:   0%|          | 0/128 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4cbf4c4f6eae492baff5b46c1ceefeeb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating Fold 5:   0%|          | 0/32 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f45a1db5cae24df8a216d8dc3dc1ba50"}},"metadata":{}},{"name":"stdout","text":"\nFold 5 Precision: 0.8503, Recall: 0.8433, F1-Score: 0.8316\n\n\nOverall Classification Report:\n              precision    recall  f1-score   support\n\n           B     0.8851    0.8506    0.8675       154\n           E     0.9054    0.9306    0.9178        72\n     NonGrad     0.8182    0.7200    0.7660        50\n          SB     0.8543    0.9195    0.8857       236\n        SB_X     0.8158    0.6200    0.7045        50\n          SW     0.8247    0.7547    0.7882       106\n        SW_X     0.8333    1.0000    0.9091        50\n           W     0.7739    0.7479    0.7607       119\n        XorB     0.8807    0.8708    0.8757       178\n        XorE     0.9535    0.8723    0.9111        47\n       XorSB     0.8077    0.8873    0.8456        71\n       XorSW     1.0000    0.8936    0.9438        47\n        XorW     0.8036    0.9574    0.8738        47\n          _X     0.7600    0.7917    0.7755        48\n\n    accuracy                         0.8510      1275\n   macro avg     0.8512    0.8440    0.8446      1275\nweighted avg     0.8519    0.8510    0.8495      1275\n\nOverall Confusion Matrix:\n[[131   1   0  10   0   0   0   6   5   0   0   0   1   0]\n [  0  67   1   1   0   0   0   1   0   1   1   0   0   0]\n [  1   1  36   3   0   1   0   3   3   1   1   0   0   0]\n [  5   0   0 217   7   1   0   2   1   0   2   0   1   0]\n [  0   0   0  17  31   0   0   0   1   0   0   0   0   1]\n [  0   0   0   1   0  80  10  12   0   0   0   0   2   1]\n [  0   0   0   0   0   0  50   0   0   0   0   0   0   0]\n [ 10   0   2   1   0  15   0  89   1   0   0   0   1   0]\n [  1   0   0   1   0   0   0   0 155   0  10   0   1  10]\n [  0   5   0   0   0   0   0   0   0  41   1   0   0   0]\n [  0   0   0   3   0   0   0   0   5   0  63   0   0   0]\n [  0   0   0   0   0   0   0   0   0   0   0  42   5   0]\n [  0   0   0   0   0   0   0   2   0   0   0   0  45   0]\n [  0   0   5   0   0   0   0   0   5   0   0   0   0  38]]\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}